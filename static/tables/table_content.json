[
    {
        "Method": "GPT-4o",
        "Mean Rank": 2.83,
        "MCOT": 62.18,
        "Multi-image VQA": 56.39,
        "Captioning": 32.56,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 47.86
    },
    {
        "Method": "LLaVA-Next-Qwen 110B",
        "Mean Rank": 3.16,
        "MCOT": 40.43,
        "Multi-image VQA": 0,
        "Captioning": 27.18,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 60.03
    },
    {
        "Method": "LLaVA-Next-Llama3-8B",
        "Mean Rank": 3.16,
        "MCOT": 20.03,
        "Multi-image VQA": 0,
        "Captioning": 28.69,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 39.63
    },
    {
        "Method": "VILA-Llama3-8B",
        "Mean Rank": 4.0,
        "MCOT": 8.66,
        "Multi-image VQA": 24.19,
        "Captioning": 33.79,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 21.38
    },
    {
        "Method": "Mantis-Idefics2-8B",
        "Mean Rank": 4.5,
        "MCOT": 5.25,
        "Multi-image VQA": 19.9,
        "Captioning": 33.34,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 24.87
    },
    {
        "Method": "GPT-4V",
        "Mean Rank": 4.67,
        "MCOT": 49.34,
        "Multi-image VQA": 48.7,
        "Captioning": 11.24,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 44.73
    },
    {
        "Method": "BEiT3 Large-0.7B",
        "Mean Rank": 5.16,
        "MCOT": 4.1,
        "Multi-image VQA": 0,
        "Captioning": 30.9,
        "Text R@1": 65.9,
        "Image R@1": 56.2,
        "VQA + Hall. Trig.": 34.21
    },
    {
        "Method": "Blip-2-FlanXXL-12B",
        "Mean Rank": 6.33,
        "MCOT": 3.13,
        "Multi-image VQA": 0,
        "Captioning": 26.0,
        "Text R@1": 63.78,
        "Image R@1": 59.97,
        "VQA + Hall. Trig.": 20.56
    },
    {
        "Method": "CogVLM v2 (Llama3)-19B",
        "Mean Rank": 8.33,
        "MCOT": 8.73,
        "Multi-image VQA": 0,
        "Captioning": 30.31,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 38.48
    },
    {
        "Method": "InstructBLIP-Flan-T5-XXL-12B",
        "Mean Rank": 8.5,
        "MCOT": 4.31,
        "Multi-image VQA": 0,
        "Captioning": 0.46,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 24.83
    },
    {
        "Method": "MiniGPT4-Vicuna13B",
        "Mean Rank": 9.0,
        "MCOT": 3.73,
        "Multi-image VQA": 0,
        "Captioning": 16.21,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 23.39
    },
    {
        "Method": "mPLUG-Owl v2-9.2B",
        "Mean Rank": 9.5,
        "MCOT": 7.07,
        "Multi-image VQA": 0,
        "Captioning": 26.74,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 9.53
    },
    {
        "Method": "MiniGPT4-Llama2-7B",
        "Mean Rank": 10.0,
        "MCOT": 3.69,
        "Multi-image VQA": 0,
        "Captioning": 20.91,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 15.27
    },
    {
        "Method": "mPLUG-Owl-7.2B",
        "Mean Rank": 11.83,
        "MCOT": 3.19,
        "Multi-image VQA": 0,
        "Captioning": 14.68,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 8.05
    },
    {
        "Method": "Human",
        "Mean Rank": "-",
        "MCOT": 84.0,
        "Multi-image VQA": 78.9,
        "Captioning": 85.71,
        "Text R@1": 0,
        "Image R@1": 0,
        "VQA + Hall. Trig.": 84.61
    },
    {
        "Method": "Random Basline",
        "Mean Rank": "-",
        "MCOT": 0.0,
        "Multi-image VQA": 16.56,
        "Captioning": 0,
        "Text R@1": 0.01,
        "Image R@1": 0.02,
        "VQA + Hall. Trig.": 0.83
    }
]